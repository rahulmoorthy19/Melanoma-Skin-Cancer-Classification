{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "CNN+Graph+Embedding.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTeOEW6KTejC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNhJtzMfTg6f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "57398ace-457f-4a6a-c717-c6c89bf28364"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nen4cwwDTejM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rag=np.load(\"/content/drive/My Drive/rag_features_small.npy\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "maeG-WDYTejW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cnn_features=pd.read_csv(\"/content/drive/My Drive/cnn_features_large.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dahXX09uTejd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding=np.load(\"/content/drive/My Drive/graph_embedding.npy\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMfhjncVTejk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cnn_features.drop(['Unnamed: 0'],inplace=True,axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVfCc6rxTejq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cnn_features=cnn_features.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QN-7BqP4Tejv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "05a80ac2-2206-4ed7-e820-c85cd6781036"
      },
      "source": [
        "cnn_features.shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10015, 32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cG1Xa8OTTej1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "total_features=np.hstack((rag,cnn_features,embedding))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X40egbDMTej-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "22c34f31-248b-4f32-cbcf-7317bb19cf51"
      },
      "source": [
        "total_features.shape"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10015, 6832)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6A4LGG_TekE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_Y_orig(labels_loc):\n",
        "    #output_list=list()\n",
        "    Y_df = pd.read_csv(labels_loc)\n",
        "    Y_df=Y_df.iloc[:,1:]\n",
        "#     for index,row in Y_df.iterrows():\n",
        "#         if row[\"MEL\"]==1:\n",
        "#             output_list.append(0)\n",
        "#         elif row[\"NV\"]==1:\n",
        "#             output_list.append(1)\n",
        "#         elif row[\"BCC\"]==1:\n",
        "#             output_list.append(2)\n",
        "#         elif row[\"AKIEC\"]==1:\n",
        "#             output_list.append(3)\n",
        "#         elif row[\"BKL\"]==1:\n",
        "#             output_list.append(4)\n",
        "#         elif row[\"DF\"]==1:\n",
        "#             output_list.append(5)\n",
        "#         elif row[\"VASC\"]==1:\n",
        "#             output_list.append(6)\n",
        "    return Y_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XRzttrVTekK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels_loc = '/content/drive/My Drive/ISIC2018_target/ISIC2018_Task3_Training_GroundTruth.csv'\n",
        "Y_orig = get_Y_orig(labels_loc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NojTq0OnTekQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "outputId": "06ce419f-2ecc-410b-855f-72ccc1182a16"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NadbE4ASTekU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "d57fa68d-99f8-4a9c-a697-318b7c30f0d6"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(12, input_dim=6832, activation='relu'))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(7, activation='softmax'))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pag7JZtnTekZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "8704f9e7-1a33-4337-b4e9-564b11eae91f"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqnudjtgTekd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_X,val_X,train_Y,val_Y= train_test_split(total_features, Y_orig, test_size=0.2, shuffle= True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBMy_eD2Tekh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "930099c1-3131-4d2d-d204-034da0ddacf8"
      },
      "source": [
        "model.fit(train_X, train_Y, epochs=100, batch_size=64,shuffle=True)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Epoch 1/100\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "8012/8012 [==============================] - 2s 208us/step - loss: 1.2245 - acc: 0.6534\n",
            "Epoch 2/100\n",
            "8012/8012 [==============================] - 1s 112us/step - loss: 0.6349 - acc: 0.8043\n",
            "Epoch 3/100\n",
            "8012/8012 [==============================] - 1s 83us/step - loss: 0.3808 - acc: 0.9073\n",
            "Epoch 4/100\n",
            "8012/8012 [==============================] - 1s 80us/step - loss: 0.2661 - acc: 0.9350\n",
            "Epoch 5/100\n",
            "8012/8012 [==============================] - 1s 83us/step - loss: 0.2037 - acc: 0.9465\n",
            "Epoch 6/100\n",
            "8012/8012 [==============================] - 1s 83us/step - loss: 0.1649 - acc: 0.9568\n",
            "Epoch 7/100\n",
            "8012/8012 [==============================] - 1s 85us/step - loss: 0.1370 - acc: 0.9623\n",
            "Epoch 8/100\n",
            "8012/8012 [==============================] - 1s 84us/step - loss: 0.1070 - acc: 0.9695\n",
            "Epoch 9/100\n",
            "8012/8012 [==============================] - 1s 83us/step - loss: 0.0819 - acc: 0.9797\n",
            "Epoch 10/100\n",
            "8012/8012 [==============================] - 1s 105us/step - loss: 0.0661 - acc: 0.9849\n",
            "Epoch 11/100\n",
            "8012/8012 [==============================] - 1s 109us/step - loss: 0.0564 - acc: 0.9871\n",
            "Epoch 12/100\n",
            "8012/8012 [==============================] - 1s 95us/step - loss: 0.0479 - acc: 0.9901\n",
            "Epoch 13/100\n",
            "8012/8012 [==============================] - 1s 89us/step - loss: 0.0417 - acc: 0.9924\n",
            "Epoch 14/100\n",
            "8012/8012 [==============================] - 1s 81us/step - loss: 0.0366 - acc: 0.9930\n",
            "Epoch 15/100\n",
            "8012/8012 [==============================] - 1s 82us/step - loss: 0.0325 - acc: 0.9954\n",
            "Epoch 16/100\n",
            "8012/8012 [==============================] - 1s 81us/step - loss: 0.0287 - acc: 0.9949\n",
            "Epoch 17/100\n",
            "8012/8012 [==============================] - 1s 83us/step - loss: 0.0252 - acc: 0.9961\n",
            "Epoch 18/100\n",
            "8012/8012 [==============================] - 1s 84us/step - loss: 0.0220 - acc: 0.9970\n",
            "Epoch 19/100\n",
            "8012/8012 [==============================] - 1s 80us/step - loss: 0.0198 - acc: 0.9976\n",
            "Epoch 20/100\n",
            "8012/8012 [==============================] - 1s 83us/step - loss: 0.0175 - acc: 0.9978\n",
            "Epoch 21/100\n",
            "8012/8012 [==============================] - 1s 84us/step - loss: 0.0158 - acc: 0.9979\n",
            "Epoch 22/100\n",
            "8012/8012 [==============================] - 1s 85us/step - loss: 0.0144 - acc: 0.9986\n",
            "Epoch 23/100\n",
            "8012/8012 [==============================] - 1s 82us/step - loss: 0.0122 - acc: 0.9990\n",
            "Epoch 24/100\n",
            "8012/8012 [==============================] - 1s 83us/step - loss: 0.0107 - acc: 0.9990\n",
            "Epoch 25/100\n",
            "8012/8012 [==============================] - 1s 84us/step - loss: 0.0095 - acc: 0.9993\n",
            "Epoch 26/100\n",
            "8012/8012 [==============================] - 1s 84us/step - loss: 0.0082 - acc: 0.9993\n",
            "Epoch 27/100\n",
            "8012/8012 [==============================] - 1s 86us/step - loss: 0.0074 - acc: 0.9995\n",
            "Epoch 28/100\n",
            "8012/8012 [==============================] - 1s 79us/step - loss: 0.0063 - acc: 0.9998\n",
            "Epoch 29/100\n",
            "8012/8012 [==============================] - 1s 81us/step - loss: 0.0056 - acc: 0.9998\n",
            "Epoch 30/100\n",
            "8012/8012 [==============================] - 1s 82us/step - loss: 0.0049 - acc: 0.9999\n",
            "Epoch 31/100\n",
            "8012/8012 [==============================] - 1s 82us/step - loss: 0.0044 - acc: 1.0000\n",
            "Epoch 32/100\n",
            "8012/8012 [==============================] - 1s 81us/step - loss: 0.0039 - acc: 1.0000\n",
            "Epoch 33/100\n",
            "8012/8012 [==============================] - 1s 80us/step - loss: 0.0035 - acc: 1.0000\n",
            "Epoch 34/100\n",
            "8012/8012 [==============================] - 1s 85us/step - loss: 0.0030 - acc: 1.0000\n",
            "Epoch 35/100\n",
            "8012/8012 [==============================] - 1s 87us/step - loss: 0.0027 - acc: 1.0000\n",
            "Epoch 36/100\n",
            "8012/8012 [==============================] - 1s 84us/step - loss: 0.0024 - acc: 1.0000\n",
            "Epoch 37/100\n",
            "8012/8012 [==============================] - 1s 86us/step - loss: 0.0022 - acc: 1.0000\n",
            "Epoch 38/100\n",
            "8012/8012 [==============================] - 1s 84us/step - loss: 0.0020 - acc: 1.0000\n",
            "Epoch 39/100\n",
            "8012/8012 [==============================] - 1s 84us/step - loss: 0.0018 - acc: 1.0000\n",
            "Epoch 40/100\n",
            "8012/8012 [==============================] - 1s 82us/step - loss: 0.0016 - acc: 1.0000\n",
            "Epoch 41/100\n",
            "8012/8012 [==============================] - 1s 84us/step - loss: 0.0015 - acc: 1.0000\n",
            "Epoch 42/100\n",
            "8012/8012 [==============================] - 1s 82us/step - loss: 0.0013 - acc: 1.0000\n",
            "Epoch 43/100\n",
            "8012/8012 [==============================] - 1s 84us/step - loss: 0.0012 - acc: 1.0000\n",
            "Epoch 44/100\n",
            "8012/8012 [==============================] - 1s 82us/step - loss: 0.0011 - acc: 1.0000\n",
            "Epoch 45/100\n",
            "8012/8012 [==============================] - 1s 82us/step - loss: 9.6910e-04 - acc: 1.0000\n",
            "Epoch 46/100\n",
            "8012/8012 [==============================] - 1s 79us/step - loss: 9.0439e-04 - acc: 1.0000\n",
            "Epoch 47/100\n",
            "8012/8012 [==============================] - 1s 84us/step - loss: 8.1692e-04 - acc: 1.0000\n",
            "Epoch 48/100\n",
            "8012/8012 [==============================] - 1s 82us/step - loss: 7.2588e-04 - acc: 1.0000\n",
            "Epoch 49/100\n",
            "8012/8012 [==============================] - 1s 88us/step - loss: 6.5371e-04 - acc: 1.0000\n",
            "Epoch 50/100\n",
            "8012/8012 [==============================] - 1s 85us/step - loss: 6.0430e-04 - acc: 1.0000\n",
            "Epoch 51/100\n",
            "8012/8012 [==============================] - 1s 87us/step - loss: 5.5481e-04 - acc: 1.0000\n",
            "Epoch 52/100\n",
            "8012/8012 [==============================] - 1s 83us/step - loss: 5.0520e-04 - acc: 1.0000\n",
            "Epoch 53/100\n",
            "8012/8012 [==============================] - 1s 85us/step - loss: 4.6253e-04 - acc: 1.0000\n",
            "Epoch 54/100\n",
            "8012/8012 [==============================] - 1s 86us/step - loss: 4.2086e-04 - acc: 1.0000\n",
            "Epoch 55/100\n",
            "8012/8012 [==============================] - 1s 82us/step - loss: 3.9228e-04 - acc: 1.0000\n",
            "Epoch 56/100\n",
            "8012/8012 [==============================] - 1s 83us/step - loss: 3.5606e-04 - acc: 1.0000\n",
            "Epoch 57/100\n",
            "8012/8012 [==============================] - 1s 86us/step - loss: 3.3130e-04 - acc: 1.0000\n",
            "Epoch 58/100\n",
            "8012/8012 [==============================] - 1s 81us/step - loss: 3.0649e-04 - acc: 1.0000\n",
            "Epoch 59/100\n",
            "8012/8012 [==============================] - 1s 80us/step - loss: 2.7676e-04 - acc: 1.0000\n",
            "Epoch 60/100\n",
            "8012/8012 [==============================] - 1s 84us/step - loss: 2.5656e-04 - acc: 1.0000\n",
            "Epoch 61/100\n",
            "8012/8012 [==============================] - 1s 84us/step - loss: 2.3730e-04 - acc: 1.0000\n",
            "Epoch 62/100\n",
            "8012/8012 [==============================] - 1s 87us/step - loss: 2.1999e-04 - acc: 1.0000\n",
            "Epoch 63/100\n",
            "8012/8012 [==============================] - 1s 89us/step - loss: 1.9678e-04 - acc: 1.0000\n",
            "Epoch 64/100\n",
            "8012/8012 [==============================] - 1s 84us/step - loss: 1.8773e-04 - acc: 1.0000\n",
            "Epoch 65/100\n",
            "8012/8012 [==============================] - 1s 84us/step - loss: 1.6942e-04 - acc: 1.0000\n",
            "Epoch 66/100\n",
            "8012/8012 [==============================] - 1s 85us/step - loss: 1.5466e-04 - acc: 1.0000\n",
            "Epoch 67/100\n",
            "8012/8012 [==============================] - 1s 83us/step - loss: 1.4305e-04 - acc: 1.0000\n",
            "Epoch 68/100\n",
            "8012/8012 [==============================] - 1s 85us/step - loss: 1.3114e-04 - acc: 1.0000\n",
            "Epoch 69/100\n",
            "8012/8012 [==============================] - 1s 84us/step - loss: 1.2159e-04 - acc: 1.0000\n",
            "Epoch 70/100\n",
            "8012/8012 [==============================] - 1s 81us/step - loss: 1.1301e-04 - acc: 1.0000\n",
            "Epoch 71/100\n",
            "8012/8012 [==============================] - 1s 82us/step - loss: 1.0358e-04 - acc: 1.0000\n",
            "Epoch 72/100\n",
            "8012/8012 [==============================] - 1s 83us/step - loss: 9.5797e-05 - acc: 1.0000\n",
            "Epoch 73/100\n",
            "8012/8012 [==============================] - 1s 82us/step - loss: 8.7855e-05 - acc: 1.0000\n",
            "Epoch 74/100\n",
            "8012/8012 [==============================] - 1s 82us/step - loss: 8.2071e-05 - acc: 1.0000\n",
            "Epoch 75/100\n",
            "8012/8012 [==============================] - 1s 83us/step - loss: 7.6835e-05 - acc: 1.0000\n",
            "Epoch 76/100\n",
            "8012/8012 [==============================] - 1s 86us/step - loss: 7.1176e-05 - acc: 1.0000\n",
            "Epoch 77/100\n",
            "8012/8012 [==============================] - 1s 82us/step - loss: 6.4910e-05 - acc: 1.0000\n",
            "Epoch 78/100\n",
            "8012/8012 [==============================] - 1s 83us/step - loss: 6.0552e-05 - acc: 1.0000\n",
            "Epoch 79/100\n",
            "8012/8012 [==============================] - 1s 84us/step - loss: 5.5329e-05 - acc: 1.0000\n",
            "Epoch 80/100\n",
            "8012/8012 [==============================] - 1s 83us/step - loss: 5.1150e-05 - acc: 1.0000\n",
            "Epoch 81/100\n",
            "8012/8012 [==============================] - 1s 85us/step - loss: 4.8086e-05 - acc: 1.0000\n",
            "Epoch 82/100\n",
            "8012/8012 [==============================] - 1s 80us/step - loss: 4.4019e-05 - acc: 1.0000\n",
            "Epoch 83/100\n",
            "8012/8012 [==============================] - 1s 84us/step - loss: 4.1230e-05 - acc: 1.0000\n",
            "Epoch 84/100\n",
            "8012/8012 [==============================] - 1s 87us/step - loss: 3.7977e-05 - acc: 1.0000\n",
            "Epoch 85/100\n",
            "8012/8012 [==============================] - 1s 83us/step - loss: 3.4846e-05 - acc: 1.0000\n",
            "Epoch 86/100\n",
            "8012/8012 [==============================] - 1s 85us/step - loss: 3.2652e-05 - acc: 1.0000\n",
            "Epoch 87/100\n",
            "8012/8012 [==============================] - 1s 84us/step - loss: 3.0285e-05 - acc: 1.0000\n",
            "Epoch 88/100\n",
            "8012/8012 [==============================] - 1s 86us/step - loss: 2.8107e-05 - acc: 1.0000\n",
            "Epoch 89/100\n",
            "8012/8012 [==============================] - 1s 83us/step - loss: 2.5656e-05 - acc: 1.0000\n",
            "Epoch 90/100\n",
            "8012/8012 [==============================] - 1s 85us/step - loss: 2.3807e-05 - acc: 1.0000\n",
            "Epoch 91/100\n",
            "8012/8012 [==============================] - 1s 81us/step - loss: 2.2588e-05 - acc: 1.0000\n",
            "Epoch 92/100\n",
            "8012/8012 [==============================] - 1s 82us/step - loss: 2.0792e-05 - acc: 1.0000\n",
            "Epoch 93/100\n",
            "8012/8012 [==============================] - 1s 84us/step - loss: 1.9323e-05 - acc: 1.0000\n",
            "Epoch 94/100\n",
            "8012/8012 [==============================] - 1s 84us/step - loss: 1.8075e-05 - acc: 1.0000\n",
            "Epoch 95/100\n",
            "8012/8012 [==============================] - 1s 85us/step - loss: 1.6637e-05 - acc: 1.0000\n",
            "Epoch 96/100\n",
            "8012/8012 [==============================] - 1s 83us/step - loss: 1.5341e-05 - acc: 1.0000\n",
            "Epoch 97/100\n",
            "8012/8012 [==============================] - 1s 84us/step - loss: 1.4238e-05 - acc: 1.0000\n",
            "Epoch 98/100\n",
            "8012/8012 [==============================] - 1s 86us/step - loss: 1.3272e-05 - acc: 1.0000\n",
            "Epoch 99/100\n",
            "8012/8012 [==============================] - 1s 82us/step - loss: 1.2487e-05 - acc: 1.0000\n",
            "Epoch 100/100\n",
            "8012/8012 [==============================] - 1s 84us/step - loss: 1.1523e-05 - acc: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff4735dac18>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBwsSYY_Tekl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "2af38976-cddb-46fc-be11-73b1d22b615d"
      },
      "source": [
        "_, accuracy = model.evaluate(val_X, val_Y)\n",
        "print('Accuracy: %.2f' % (accuracy*100))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2003/2003 [==============================] - 0s 70us/step\n",
            "Accuracy: 95.26\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PIMc7UpaTekp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "outputId": "e168cbea-b8c3-4b04-93d6-663c88b9fc86"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 12)                81996     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 8)                 104       \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 7)                 63        \n",
            "=================================================================\n",
            "Total params: 82,163\n",
            "Trainable params: 82,163\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUioro7wTeks",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions=model.predict_classes(val_X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7_yKJ1ETekx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions=predictions.tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6NZEbb-Tek2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output_list=list()\n",
        "for index,row in val_Y.iterrows():\n",
        "    if row[\"MEL\"]==1:\n",
        "        output_list.append(0)\n",
        "    elif row[\"NV\"]==1:\n",
        "        output_list.append(1)\n",
        "    elif row[\"BCC\"]==1:\n",
        "        output_list.append(2)\n",
        "    elif row[\"AKIEC\"]==1:\n",
        "        output_list.append(3)\n",
        "    elif row[\"BKL\"]==1:\n",
        "        output_list.append(4)\n",
        "    elif row[\"DF\"]==1:\n",
        "        output_list.append(5)\n",
        "    elif row[\"VASC\"]==1:\n",
        "        output_list.append(6)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwLPGFu_Tek6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBEKgcvZTek_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "outputId": "273f63b4-a0ba-4b01-d9aa-139dab6cb3e0"
      },
      "source": [
        "classification_report(output_list,predictions,output_dict=True)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'0': {'f1-score': 0.8616780045351474,\n",
              "  'precision': 0.867579908675799,\n",
              "  'recall': 0.8558558558558559,\n",
              "  'support': 222},\n",
              " '1': {'f1-score': 0.9705553484904957,\n",
              "  'precision': 0.9644444444444444,\n",
              "  'recall': 0.9767441860465116,\n",
              "  'support': 1333},\n",
              " '2': {'f1-score': 0.9805825242718447,\n",
              "  'precision': 0.9805825242718447,\n",
              "  'recall': 0.9805825242718447,\n",
              "  'support': 103},\n",
              " '3': {'f1-score': 0.9763779527559054,\n",
              "  'precision': 0.9841269841269841,\n",
              "  'recall': 0.96875,\n",
              "  'support': 64},\n",
              " '4': {'f1-score': 0.9082774049217003,\n",
              "  'precision': 0.9311926605504587,\n",
              "  'recall': 0.8864628820960698,\n",
              "  'support': 229},\n",
              " '5': {'f1-score': 0.9583333333333334,\n",
              "  'precision': 1.0,\n",
              "  'recall': 0.92,\n",
              "  'support': 25},\n",
              " '6': {'f1-score': 1.0, 'precision': 1.0, 'recall': 1.0, 'support': 27},\n",
              " 'accuracy': 0.9525711432850724,\n",
              " 'macro avg': {'f1-score': 0.950829224044061,\n",
              "  'precision': 0.9611323602956473,\n",
              "  'recall': 0.9411993497528973,\n",
              "  'support': 2003},\n",
              " 'weighted avg': {'f1-score': 0.9523139513636616,\n",
              "  'precision': 0.952288782037271,\n",
              "  'recall': 0.9525711432850724,\n",
              "  'support': 2003}}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nsk3isMIUcGN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}