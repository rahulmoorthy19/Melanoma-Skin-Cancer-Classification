{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_features=np.load(\"rag_features.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_features=pd.read_csv(\"cnn_features_large.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.576777</td>\n",
       "      <td>-3.945932</td>\n",
       "      <td>4.803016</td>\n",
       "      <td>3.189036</td>\n",
       "      <td>-2.080729</td>\n",
       "      <td>-1.822992</td>\n",
       "      <td>-1.415842</td>\n",
       "      <td>1.251550</td>\n",
       "      <td>-1.122755</td>\n",
       "      <td>...</td>\n",
       "      <td>2.900688</td>\n",
       "      <td>0.836991</td>\n",
       "      <td>-0.162772</td>\n",
       "      <td>0.327203</td>\n",
       "      <td>-3.030703</td>\n",
       "      <td>4.946615</td>\n",
       "      <td>-2.560668</td>\n",
       "      <td>-0.702272</td>\n",
       "      <td>0.138903</td>\n",
       "      <td>2.183795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.273053</td>\n",
       "      <td>-2.931379</td>\n",
       "      <td>6.150136</td>\n",
       "      <td>3.694960</td>\n",
       "      <td>-4.095263</td>\n",
       "      <td>-1.475067</td>\n",
       "      <td>-2.136545</td>\n",
       "      <td>1.437015</td>\n",
       "      <td>-2.896256</td>\n",
       "      <td>...</td>\n",
       "      <td>2.814346</td>\n",
       "      <td>-0.179391</td>\n",
       "      <td>-1.063998</td>\n",
       "      <td>-0.518706</td>\n",
       "      <td>-4.148804</td>\n",
       "      <td>3.832036</td>\n",
       "      <td>-3.757436</td>\n",
       "      <td>2.780955</td>\n",
       "      <td>0.713002</td>\n",
       "      <td>4.008554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-5.547634</td>\n",
       "      <td>-7.335995</td>\n",
       "      <td>4.485065</td>\n",
       "      <td>3.809859</td>\n",
       "      <td>-1.156559</td>\n",
       "      <td>-0.141361</td>\n",
       "      <td>-3.035493</td>\n",
       "      <td>0.800622</td>\n",
       "      <td>-0.905164</td>\n",
       "      <td>...</td>\n",
       "      <td>4.025711</td>\n",
       "      <td>4.258149</td>\n",
       "      <td>-1.408270</td>\n",
       "      <td>-1.450558</td>\n",
       "      <td>-3.353894</td>\n",
       "      <td>4.266500</td>\n",
       "      <td>-3.481836</td>\n",
       "      <td>-5.016182</td>\n",
       "      <td>0.472003</td>\n",
       "      <td>1.710162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>-2.219563</td>\n",
       "      <td>-3.196903</td>\n",
       "      <td>5.448789</td>\n",
       "      <td>3.788954</td>\n",
       "      <td>-1.905776</td>\n",
       "      <td>-0.782672</td>\n",
       "      <td>-2.127305</td>\n",
       "      <td>-0.263901</td>\n",
       "      <td>-1.591551</td>\n",
       "      <td>...</td>\n",
       "      <td>2.539538</td>\n",
       "      <td>0.982034</td>\n",
       "      <td>-0.976380</td>\n",
       "      <td>-0.613500</td>\n",
       "      <td>-2.164868</td>\n",
       "      <td>3.118608</td>\n",
       "      <td>-2.345061</td>\n",
       "      <td>-0.255565</td>\n",
       "      <td>1.632033</td>\n",
       "      <td>3.254106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>-6.854525</td>\n",
       "      <td>-7.804424</td>\n",
       "      <td>5.984237</td>\n",
       "      <td>3.427894</td>\n",
       "      <td>1.028706</td>\n",
       "      <td>-1.682487</td>\n",
       "      <td>-1.388808</td>\n",
       "      <td>0.809004</td>\n",
       "      <td>3.089412</td>\n",
       "      <td>...</td>\n",
       "      <td>0.865692</td>\n",
       "      <td>3.909653</td>\n",
       "      <td>0.915837</td>\n",
       "      <td>1.075717</td>\n",
       "      <td>0.670368</td>\n",
       "      <td>6.161496</td>\n",
       "      <td>0.199500</td>\n",
       "      <td>-10.325129</td>\n",
       "      <td>0.261942</td>\n",
       "      <td>-0.152172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0         0         1         2         3         4         5  \\\n",
       "0           0 -2.576777 -3.945932  4.803016  3.189036 -2.080729 -1.822992   \n",
       "1           1 -1.273053 -2.931379  6.150136  3.694960 -4.095263 -1.475067   \n",
       "2           2 -5.547634 -7.335995  4.485065  3.809859 -1.156559 -0.141361   \n",
       "3           3 -2.219563 -3.196903  5.448789  3.788954 -1.905776 -0.782672   \n",
       "4           4 -6.854525 -7.804424  5.984237  3.427894  1.028706 -1.682487   \n",
       "\n",
       "          6         7         8  ...        22        23        24        25  \\\n",
       "0 -1.415842  1.251550 -1.122755  ...  2.900688  0.836991 -0.162772  0.327203   \n",
       "1 -2.136545  1.437015 -2.896256  ...  2.814346 -0.179391 -1.063998 -0.518706   \n",
       "2 -3.035493  0.800622 -0.905164  ...  4.025711  4.258149 -1.408270 -1.450558   \n",
       "3 -2.127305 -0.263901 -1.591551  ...  2.539538  0.982034 -0.976380 -0.613500   \n",
       "4 -1.388808  0.809004  3.089412  ...  0.865692  3.909653  0.915837  1.075717   \n",
       "\n",
       "         26        27        28         29        30        31  \n",
       "0 -3.030703  4.946615 -2.560668  -0.702272  0.138903  2.183795  \n",
       "1 -4.148804  3.832036 -3.757436   2.780955  0.713002  4.008554  \n",
       "2 -3.353894  4.266500 -3.481836  -5.016182  0.472003  1.710162  \n",
       "3 -2.164868  3.118608 -2.345061  -0.255565  1.632033  3.254106  \n",
       "4  0.670368  6.161496  0.199500 -10.325129  0.261942 -0.152172  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_features.drop([\"Unnamed: 0\"],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_features=cnn_features.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10015, 12100)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10015, 32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_features=np.hstack((rag_features,cnn_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10015, 12132)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Y_orig(labels_loc):\n",
    "    #output_list=list()\n",
    "    Y_df = pd.read_csv(labels_loc)\n",
    "    Y_df=Y_df.iloc[:,1:]\n",
    "#     for index,row in Y_df.iterrows():\n",
    "#         if row[\"MEL\"]==1:\n",
    "#             output_list.append(0)\n",
    "#         elif row[\"NV\"]==1:\n",
    "#             output_list.append(1)\n",
    "#         elif row[\"BCC\"]==1:\n",
    "#             output_list.append(2)\n",
    "#         elif row[\"AKIEC\"]==1:\n",
    "#             output_list.append(3)\n",
    "#         elif row[\"BKL\"]==1:\n",
    "#             output_list.append(4)\n",
    "#         elif row[\"DF\"]==1:\n",
    "#             output_list.append(5)\n",
    "#         elif row[\"VASC\"]==1:\n",
    "#             output_list.append(6)\n",
    "    return Y_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_loc = 'ISIC2018_Task3_Training_GroundTruth/ISIC2018_Task3_Training_GroundTruth.csv'\n",
    "\n",
    "Y_orig = get_Y_orig(labels_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=12132, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(7, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_X,val_X,train_Y,val_Y= train_test_split(total_features, Y_orig, test_size=0.2, shuffle= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8012/8012 [==============================] - 2s 277us/step - loss: 1.1817 - accuracy: 0.6030\n",
      "Epoch 2/50\n",
      "8012/8012 [==============================] - 2s 260us/step - loss: 0.4374 - accuracy: 0.8628\n",
      "Epoch 3/50\n",
      "8012/8012 [==============================] - 2s 293us/step - loss: 0.2995 - accuracy: 0.9217\n",
      "Epoch 4/50\n",
      "8012/8012 [==============================] - 2s 229us/step - loss: 0.2255 - accuracy: 0.9443\n",
      "Epoch 5/50\n",
      "8012/8012 [==============================] - 2s 238us/step - loss: 0.1777 - accuracy: 0.9551\n",
      "Epoch 6/50\n",
      "8012/8012 [==============================] - 2s 233us/step - loss: 0.1422 - accuracy: 0.9608\n",
      "Epoch 7/50\n",
      "8012/8012 [==============================] - 2s 271us/step - loss: 0.1150 - accuracy: 0.9680\n",
      "Epoch 8/50\n",
      "8012/8012 [==============================] - 2s 290us/step - loss: 0.0928 - accuracy: 0.9749\n",
      "Epoch 9/50\n",
      "8012/8012 [==============================] - 2s 295us/step - loss: 0.0738 - accuracy: 0.9799\n",
      "Epoch 10/50\n",
      "8012/8012 [==============================] - 2s 211us/step - loss: 0.0580 - accuracy: 0.9853\n",
      "Epoch 11/50\n",
      "8012/8012 [==============================] - 2s 206us/step - loss: 0.0455 - accuracy: 0.9910\n",
      "Epoch 12/50\n",
      "8012/8012 [==============================] - 2s 260us/step - loss: 0.0367 - accuracy: 0.9933\n",
      "Epoch 13/50\n",
      "8012/8012 [==============================] - 2s 286us/step - loss: 0.0288 - accuracy: 0.9960\n",
      "Epoch 14/50\n",
      "8012/8012 [==============================] - 2s 244us/step - loss: 0.0236 - accuracy: 0.9975\n",
      "Epoch 15/50\n",
      "8012/8012 [==============================] - 2s 251us/step - loss: 0.0194 - accuracy: 0.9979\n",
      "Epoch 16/50\n",
      "8012/8012 [==============================] - 2s 250us/step - loss: 0.0159 - accuracy: 0.9986\n",
      "Epoch 17/50\n",
      "8012/8012 [==============================] - 2s 234us/step - loss: 0.0133 - accuracy: 0.9989\n",
      "Epoch 18/50\n",
      "8012/8012 [==============================] - 2s 236us/step - loss: 0.0111 - accuracy: 0.9993\n",
      "Epoch 19/50\n",
      "8012/8012 [==============================] - 2s 211us/step - loss: 0.0092 - accuracy: 0.9996\n",
      "Epoch 20/50\n",
      "8012/8012 [==============================] - 2s 266us/step - loss: 0.0081 - accuracy: 0.9995\n",
      "Epoch 21/50\n",
      "8012/8012 [==============================] - 2s 245us/step - loss: 0.0067 - accuracy: 0.9996\n",
      "Epoch 22/50\n",
      "8012/8012 [==============================] - 2s 248us/step - loss: 0.0057 - accuracy: 0.9996\n",
      "Epoch 23/50\n",
      "8012/8012 [==============================] - 2s 215us/step - loss: 0.0049 - accuracy: 0.9998\n",
      "Epoch 24/50\n",
      "8012/8012 [==============================] - 2s 232us/step - loss: 0.0042 - accuracy: 0.9998\n",
      "Epoch 25/50\n",
      "8012/8012 [==============================] - 2s 232us/step - loss: 0.0036 - accuracy: 0.9998\n",
      "Epoch 26/50\n",
      "8012/8012 [==============================] - 2s 241us/step - loss: 0.0032 - accuracy: 0.9998\n",
      "Epoch 27/50\n",
      "8012/8012 [==============================] - 2s 285us/step - loss: 0.0028 - accuracy: 0.9998\n",
      "Epoch 28/50\n",
      "8012/8012 [==============================] - 2s 230us/step - loss: 0.0025 - accuracy: 0.9998\n",
      "Epoch 29/50\n",
      "8012/8012 [==============================] - 2s 225us/step - loss: 0.0021 - accuracy: 0.9998\n",
      "Epoch 30/50\n",
      "8012/8012 [==============================] - 2s 244us/step - loss: 0.0019 - accuracy: 0.9999\n",
      "Epoch 31/50\n",
      "8012/8012 [==============================] - 2s 257us/step - loss: 0.0017 - accuracy: 0.9999\n",
      "Epoch 32/50\n",
      "8012/8012 [==============================] - 2s 245us/step - loss: 0.0015 - accuracy: 0.9999\n",
      "Epoch 33/50\n",
      "8012/8012 [==============================] - 2s 251us/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 34/50\n",
      "8012/8012 [==============================] - 2s 234us/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 35/50\n",
      "8012/8012 [==============================] - 2s 233us/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 36/50\n",
      "8012/8012 [==============================] - 2s 231us/step - loss: 9.7903e-04 - accuracy: 1.00000s - loss: 9.6728e-04 - accuracy\n",
      "Epoch 37/50\n",
      "8012/8012 [==============================] - 2s 235us/step - loss: 8.8824e-04 - accuracy: 1.0000\n",
      "Epoch 38/50\n",
      "8012/8012 [==============================] - 2s 261us/step - loss: 8.0338e-04 - accuracy: 1.0000\n",
      "Epoch 39/50\n",
      "8012/8012 [==============================] - 2s 266us/step - loss: 7.2556e-04 - accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "8012/8012 [==============================] - 2s 215us/step - loss: 6.6363e-04 - accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "8012/8012 [==============================] - 2s 244us/step - loss: 5.9915e-04 - accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "8012/8012 [==============================] - 2s 208us/step - loss: 5.5345e-04 - accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "8012/8012 [==============================] - 2s 239us/step - loss: 5.4198e-04 - accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "8012/8012 [==============================] - 2s 231us/step - loss: 5.2379e-04 - accuracy: 0.9999\n",
      "Epoch 45/50\n",
      "8012/8012 [==============================] - 2s 235us/step - loss: 3.9834e-04 - accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "8012/8012 [==============================] - 2s 283us/step - loss: 3.4330e-04 - accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "8012/8012 [==============================] - 2s 236us/step - loss: 3.1351e-04 - accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "8012/8012 [==============================] - 2s 221us/step - loss: 2.8481e-04 - accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "8012/8012 [==============================] - 2s 236us/step - loss: 2.5621e-04 - accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "8012/8012 [==============================] - 2s 220us/step - loss: 2.3493e-04 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x29c60516f08>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_X, train_Y, epochs=50, batch_size=64,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2003/2003 [==============================] - 1s 332us/step\n",
      "Accuracy: 94.16\n"
     ]
    }
   ],
   "source": [
    "_, accuracy = model.evaluate(val_X, val_Y)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 12)                145596    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 104       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 7)                 63        \n",
      "=================================================================\n",
      "Total params: 145,763\n",
      "Trainable params: 145,763\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=model.predict_classes(val_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=predictions.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_list=list()\n",
    "for index,row in val_Y.iterrows():\n",
    "    if row[\"MEL\"]==1:\n",
    "        output_list.append(0)\n",
    "    elif row[\"NV\"]==1:\n",
    "        output_list.append(1)\n",
    "    elif row[\"BCC\"]==1:\n",
    "        output_list.append(2)\n",
    "    elif row[\"AKIEC\"]==1:\n",
    "        output_list.append(3)\n",
    "    elif row[\"BKL\"]==1:\n",
    "        output_list.append(4)\n",
    "    elif row[\"DF\"]==1:\n",
    "        output_list.append(5)\n",
    "    elif row[\"VASC\"]==1:\n",
    "        output_list.append(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': {'precision': 0.8947368421052632,\n",
       "  'recall': 0.8018867924528302,\n",
       "  'f1-score': 0.845771144278607,\n",
       "  'support': 212},\n",
       " '1': {'precision': 0.9542857142857143,\n",
       "  'recall': 0.9723435225618632,\n",
       "  'f1-score': 0.9632299927901947,\n",
       "  'support': 1374},\n",
       " '2': {'precision': 0.96, 'recall': 0.96, 'f1-score': 0.96, 'support': 100},\n",
       " '3': {'precision': 1.0,\n",
       "  'recall': 0.9830508474576272,\n",
       "  'f1-score': 0.9914529914529915,\n",
       "  'support': 59},\n",
       " '4': {'precision': 0.8708133971291866,\n",
       "  'recall': 0.883495145631068,\n",
       "  'f1-score': 0.8771084337349399,\n",
       "  'support': 206},\n",
       " '5': {'precision': 0.9259259259259259,\n",
       "  'recall': 0.8620689655172413,\n",
       "  'f1-score': 0.8928571428571429,\n",
       "  'support': 29},\n",
       " '6': {'precision': 1.0,\n",
       "  'recall': 0.8260869565217391,\n",
       "  'f1-score': 0.9047619047619047,\n",
       "  'support': 23},\n",
       " 'accuracy': 0.9415876185721418,\n",
       " 'macro avg': {'precision': 0.9436802684922985,\n",
       "  'recall': 0.8984188900203385,\n",
       "  'f1-score': 0.9193116585536831,\n",
       "  'support': 2003},\n",
       " 'weighted avg': {'precision': 0.9411443802373199,\n",
       "  'recall': 0.9415876185721418,\n",
       "  'f1-score': 0.9409205878573627,\n",
       "  'support': 2003}}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_report(output_list,predictions,output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
